{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laptop</td>\n",
       "      <td>This laptop has exceeded my expectations. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smartphone</td>\n",
       "      <td>I am extremely satisfied with this smartphone....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headphones</td>\n",
       "      <td>These headphones are simply amazing. The sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tablet</td>\n",
       "      <td>This tablet is perfect for on-the-go entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smartwatch</td>\n",
       "      <td>This smartwatch is a great companion for fitne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product                                             review\n",
       "0      Laptop  This laptop has exceeded my expectations. The ...\n",
       "1  Smartphone  I am extremely satisfied with this smartphone....\n",
       "2  Headphones  These headphones are simply amazing. The sound...\n",
       "3      Tablet  This tablet is perfect for on-the-go entertain...\n",
       "4  Smartwatch  This smartwatch is a great companion for fitne..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.9\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}? \"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best name for a company that makes tablets can depend on various factors such as the target audience, brand values, and product positioning. Here are some suggestions:\\n\\n1. Tablio: A combination of \"tablet\" and \"ilio,\" suggesting a sense of innovation and style.\\n2. Slate Pro: Emphasizing the tablet\\'s functionality and professionalism.\\n3. ViewPad: Suggesting a clear and sharp view, which is often associated with tablets.\\n4. Tabix: A play on the word \"tab,\" conveying a sense of simplicity and ease of use.\\n5. Nexus Tablet Co.: Implies connection and integration, suggesting a tablet that bridges different aspects of life.\\n6. PaddleTech: Combining \"paddle\" (a common term for tablets) with \"tech,\" emphasizing innovation and cutting-edge technology.\\n7. DisplayZone: Highlights the tablet\\'s display capabilities and suggests a focused approach to creating an ideal viewing experience.\\n8. Fusion Table: Suggests a blend of style, functionality, and innovative features.\\n9. SlateZone: Similar to DisplayZone, but with a stronger emphasis on the tablet as a versatile tool.\\n10. TechTab: Simple and straightforward, emphasizing the company\\'s focus on technology and tablets.\\n\\nWhen choosing a name for your company, consider factors like:\\n\\n* Memorability and ease of spelling\\n* Brand identity and values alignment\\n* Uniqueness and distinctiveness from competitors\\n* Scalability and adaptability to changing markets and technologies\\n\\nRemember to conduct thorough research, test the name with your target audience, and ensure that the chosen name is available as a web domain and social media handle.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Tablet\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}? \"\n",
    ")\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following company: {company_name}. \"\n",
    ")\n",
    "# Chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe best name for a company that makes tablets can depend on various factors such as the brand identity, target audience, and values. However, here are some suggestions:\n",
      "\n",
      "1. **Tablezza**: A combination of \"tablet\" and \"beauty,\" implying that the company's products are not only functional but also aesthetically pleasing.\n",
      "2. **Tablio**: Derived from the Latin word \"tabula,\" meaning tablet or slate, this name conveys a sense of simplicity and elegance.\n",
      "3. **Padion**: A combination of \"pad\" (short for padlet) and \"ion,\" suggesting innovation and technology.\n",
      "4. **Surfacium**: This name highlights the tablet's surface interface, implying a seamless user experience.\n",
      "5. **Tabletopia**: This name evokes a sense of utopia, suggesting that tablets are not just devices but a gateway to new possibilities and connections.\n",
      "6. **Lumina Tab**: \"Lumina\" means light in Latin, implying that the company's products bring illumination and understanding to users.\n",
      "7. **Taptex**: A combination of \"tap\" (short for tablet) and \"texture,\" highlighting the tactile experience of using a tablet.\n",
      "8. **Canvasio**: This name references the idea of tablets as creative platforms, where users can express themselves freely.\n",
      "9. **PulseTablet**: This name emphasizes the dynamic energy and pulse of the company's products.\n",
      "10. **Tablezza**: An Italian-inspired name that means \"tablet\" in English, implying a sense of heritage and tradition.\n",
      "\n",
      "Ultimately, the best name for your tablet-making company will depend on your brand vision, values, and target audience. You may also consider conducting market research or brainstorming sessions to come up with a unique name that resonates with your goals.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHere is a 20-word description for one of the suggested company names:\n",
      "\n",
      "\"Tablezza: Crafted with elegance, innovation, and passion, our tablets bring beauty, connection, and understanding to those who create and share.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a 20-word description for one of the suggested company names:\\n\\n\"Tablezza: Crafted with elegance, innovation, and passion, our tablets bring beauty, connection, and understanding to those who create and share.\"'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.9\n",
    ")\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to Chinese: \"\n",
    "    \"\\n \\n {Review}. \"\n",
    ")\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt,output_key=\"Chinese_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n \\n {Chinese_review}. \"\n",
    ")\n",
    "# Chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=first_prompt,output_key=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to English\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review: \\n\\n {Review}. \"\n",
    ")\n",
    "# Chain 3\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary int the specified language:\"\n",
    "    \"\\n \\n Summary: {summary} \\n \\n Language: {language}. \"\n",
    ")\n",
    "# Chain 4\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"follow_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"Chinese_review\", \"summary\", \"language\", \"follow_up\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'This coffee maker is a lifesaver in the mornings. It brews delicious coffee quickly and easily. The programmable timer is a great feature.',\n",
       " 'Chinese_review': 'Here\\'s the translation:\\n\\n这台咖啡机是早晨的救命。它快速方便地制作出丰富口味的咖啡，而且设有定时功能很好。\\n\\nNote: I translated \"lifesaver\" to \"\" (jiu sheng), which is a common idiomatic expression in Chinese that means something or someone is very helpful or lifesaving.',\n",
       " 'summary': \"Here's the translation of the review to Chinese:\\n\\n这个咖啡机是早上的生命救生器。它迅速便捷地制作出美味的咖啡，调节时间 Programmable 是一个很好的功能。\\n\\nAlternatively, you can also translate it as:\\n\\n早晨，这个咖啡机都是我的 lifesaver。它快速方便地制作出高质量的咖啡，调时器是一种非常有用的功能。\\n\\nOr, in a more formal tone:\\n\\n这款咖啡机在早上为我提供了生命的救生。它能够迅速便捷地制作出美味的咖啡，并具备一项时间设定功能，这是使用此产品的一个大大的优势。\\n\\nNote that Chinese translations may have slightly different wording or phrasing, but the overall meaning should be similar.\",\n",
       " 'language': 'The review appears to be written in English.',\n",
       " 'follow_up': 'Here\\'s a potential follow-up response:\\n\\n\"I completely agree with this reviewer! I\\'ve been using my own coffee machine for a few months now and it has genuinely changed my morning routine. The programmable timer feature is a game-changer - it allows me to wake up to the perfect cup of coffee every time, without having to worry about manually setting the brew time.\\n\\nI also appreciate how easy it is to clean and maintain the machine. The design is sleek and compact, making it a great addition to any kitchen countertop. Overall, I\\'d highly recommend this coffee machine to anyone looking to upgrade their morning coffee game!\"\\n\\nNote that I\\'ve kept the same informal tone as the original review, while adding my own personal experience with the product.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a world-renowned physics professor. Your task is to answer student questions clearly, concisely, and accurately.\n",
    " You should explain the underlying principles in a way that is easy to understand, even for someone with limited prior knowledge. \n",
    " You should also provide examples to illustrate the concepts.\n",
    "\n",
    "Here is a question: {input}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a highly skilled mathematician, capable of solving complex problems and explaining mathematical concepts with clarity and precision. \n",
    "Your goal is to guide students through the problem-solving process, showing your work step-by-step and explaining the reasoning behind each step. \n",
    "You should also provide alternative approaches where applicable.\n",
    "\n",
    "Here is a question: {input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a knowledgeable historian with a passion for bringing the past to life. \n",
    "Your task is to answer questions about historical events, figures, and trends in a way that is engaging and informative. \n",
    "You should provide context, analyze different perspectives, and cite reliable sources to support your claims.\n",
    "\n",
    "Here is a question: {input}\"\"\"\n",
    "\n",
    "computerscience_template = \"\"\"You are an experienced computer science instructor, adept at explaining complex technical concepts in a clear and accessible manner. \n",
    "Your task is to answer student questions about programming, algorithms, data structures, and other computer science topics. \n",
    "You should provide code examples, diagrams, and analogies to help students understand the material.\n",
    "\n",
    "Here is a question: {input}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些信息会被输入router chain，路由链可以决定何时使用这个子链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"Physics\",\n",
    "        \"description\": \"Answer student questions about physics concepts and principles.\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mathematics\",\n",
    "        \"description\": \"Assist with solving math problems and explaining mathematical concepts.\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\",\n",
    "        \"description\": \"Provide insights into historical events, figures, and trends.\",\n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Computer Science\",\n",
    "        \"description\": \"Help students with programming, algorithms, and data structures.\",\n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"qwen:7b\",\n",
    "    temperature=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain # 用于将输入路由到不同的链\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser # LLM 路由链和输出解析器\n",
    "from langchain.prompts import PromptTemplate # 提示模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {} # 创建一个空字典，用于存储目标链。目标链是指根据不同的主题或任务选择的不同LLMChain。\n",
    "\n",
    "for p_info in prompt_infos: # 遍历prompt_infos列表，该列表包含了不同主题的提示信息。\n",
    "    name = p_info[\"name\"] # 从提示信息字典中提取主题名称。\n",
    "    prompt_template = p_info[\"prompt_template\"] # 从提示信息字典中提取提示模板。\n",
    "\n",
    "    # 使用提取的提示模板创建一个ChatPromptTemplate对象。ChatPromptTemplate用于定义LLMChain的输入格式。\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "    # 创建一个LLMChain对象，将之前定义的ChatPromptTemplate和LLM模型(llm)结合起来。LLMChain是Langchain中用于执行语言模型任务的核心组件。\n",
    "    chain = LLMChain(llm=llm, prompt=prompt) \n",
    "    destination_chains[name] = chain # 将链添加到目标链字典中，key为学科名称，value为对应的链\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos] # 创建一个包含所有目标（主题）描述的列表。\n",
    "destinations_str = \"\\n\".join(destinations) # 将目标描述列表连接成一个字符串，每个目标描述占一行。这个字符串用于后续的路由选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个默认的提示模板，用于处理未匹配到任何特定主题的输入。\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "# 基于默认提示模板和LLM创建一个LLMChain，用于处理未匹配到任何特定主题的输入。\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"ou are a prompt selector for a large language model. Your task is to analyze the user's input and determine which of the candidate prompts is most appropriate for generating a relevant and helpful response. Consider the topic, complexity, and required expertise when making your selection.\n",
    "\n",
    "<<FORMATTING>>The output must be a JSON object enclosed in triple backticks. The JSON object must have the following structure:\n",
    "```json\n",
    "{{{{\n",
    "\"destination: string \\ xxx name of the selected prompt\n",
    "\"next_inputs\": string \\ xxx user input, potentially rephrased\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER:\"destination\"\n",
    "REMEMBER:\"next_inputs\"\n",
    "<<CANDIDATE PROMPTS>> \n",
    "{destinations} \n",
    "<<INPUT>> \n",
    "{{input}} \n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format( # 使用MULTI_PROMPT_ROUTER_TEMPLATE模板，将目标信息填充进去\n",
    "    destinations=destinations_str # 将所有目标链的描述信息填充到模板中\n",
    ")\n",
    "router_prompt = PromptTemplate( # 创建一个PromptTemplate对象，用于定义路由链的提示\n",
    "    template=router_template, # 使用格式化后的路由模板\n",
    "    input_variables=[\"input\"], # 定义输入变量为\"input\"，即用户的输入\n",
    "    output_parser=RouterOutputParser() # 使用RouterOutputParser解析LLM的输出，提取目标链的名称和输入\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt) # 基于LLM和路由提示，创建一个LLMRouterChain对象。LLMRouterChain用于根据用户输入选择合适的目标链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiPromptChain(verbose=True, router_chain=LLMRouterChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, output_parser=RouterOutputParser(), partial_variables={}, template='ou are a prompt selector for a large language model. Your task is to analyze the user\\'s input and determine which of the candidate prompts is most appropriate for generating a relevant and helpful response. Consider the topic, complexity, and required expertise when making your selection.\\n\\n<<FORMATTING>>The output must be a JSON object enclosed in triple backticks. The JSON object must have the following structure:\\n```json\\n{{\\n\"destination: string \\\\ xxx name of the selected prompt\\n\"next_inputs\": string \\\\ xxx user input, potentially rephrased\\n}}\\n```\\n\\nREMEMBER:\"destination\"\\nREMEMBER:\"next_inputs\"\\n<<CANDIDATE PROMPTS>> \\nPhysics: Answer student questions about physics concepts and principles.\\nMathematics: Assist with solving math problems and explaining mathematical concepts.\\nHistory: Provide insights into historical events, figures, and trends.\\nComputer Science: Help students with programming, algorithms, and data structures. \\n<<INPUT>> \\n{input} \\n<< OUTPUT (remember to include the ```json)>>'), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={})), destination_chains={'Physics': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are a world-renowned physics professor. Your task is to answer student questions clearly, concisely, and accurately.\\n You should explain the underlying principles in a way that is easy to understand, even for someone with limited prior knowledge. \\n You should also provide examples to illustrate the concepts.\\n\\nHere is a question: {input}'), additional_kwargs={})]), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={}), 'Mathematics': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are a highly skilled mathematician, capable of solving complex problems and explaining mathematical concepts with clarity and precision. \\nYour goal is to guide students through the problem-solving process, showing your work step-by-step and explaining the reasoning behind each step. \\nYou should also provide alternative approaches where applicable.\\n\\nHere is a question: {input}'), additional_kwargs={})]), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={}), 'History': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are a knowledgeable historian with a passion for bringing the past to life. \\nYour task is to answer questions about historical events, figures, and trends in a way that is engaging and informative. \\nYou should provide context, analyze different perspectives, and cite reliable sources to support your claims.\\n\\nHere is a question: {input}'), additional_kwargs={})]), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={}), 'Computer Science': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an experienced computer science instructor, adept at explaining complex technical concepts in a clear and accessible manner. \\nYour task is to answer student questions about programming, algorithms, data structures, and other computer science topics. \\nYou should provide code examples, diagrams, and analogies to help students understand the material.\\n\\nHere is a question: {input}'), additional_kwargs={})]), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={})}, default_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]), llm=ChatOllama(model='qwen:7b', temperature=0.9), output_parser=StrOutputParser(), llm_kwargs={}))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiPromptChain(router_chain=router_chain,\n",
    "                 destination_chains=destination_chains,\n",
    "                 default_chain=default_chain,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the type of electromagnetic radiation that is emitted or absorbed by a perfect absorber or emitter, in other words, an object with no loss of energy due to its surface properties.\\n\\nA black body at absolute zero temperature (0 Kelvin) would emit only radiation according to Planck's law. As the temperature increases, the black body will emit a continuous spectrum of frequencies, with the peak intensity occurring at specific wavelengths corresponding to the temperature.\\n\\nHere's a diagram representing black body radiation for different temperatures:\\n\\n```\\n           Temperature:       0 K (Absolute Zero)\\n             -   Radiation only   -\\n\\n           Temperature:      300 K (Room Temperature)\\n            *    Continuous spectrum   *\\n            ** Peak intensity at specific wavelengths **\\n\\n           Temperature:     higher... (E.g., Sun's Surface)\\n             ** Increasing peak wavelength and decreasing intensity **\\n\\n```\\nIn summary, black body radiation is the emission of electromagnetic radiation by a perfect absorber or emitter at various temperatures.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Judging the quality of an AI conference like the Association for Advancing Artificial Intelligence (AAAI) can be done through multiple aspects. Here's a detailed approach:\\n\\n1. **Selection Criteria**:\\n   - **Ranking**: AAAI is well-known and has a ranking system based on peer review.\\n   - **Citation Count**: The number of times researchers引用AAAI论文 as evidence for their work can indicate quality.\\n   - **Panel Judgments**: A panel of experts in AI, including members of the AAAI organization, may evaluate submissions and conference overall.\\n\\n2. **Paper Evaluation**:\\n   - **Technical Quality**: Assess whether the proposed solutions or methods are well-designed, novel, and practical.\\n   - **Originality and Contribution**: Determine if the work adds significantly to existing knowledge in AI.\\n   - **Clarity and Presentation**: Evaluate the quality of the written paper, including the use of clear language and proper citation.\\n\\n3. **Conference Evaluation**:\\n   - **Program Quality**: Assess the overall lineup of talks and workshops, ensuring a mix of topics and expertise.\\n   - **Organizational Efficiency**: Evaluate the conference's logistical aspects, such as ease of registration, timely delivery of materials, and efficient use of venue resources.\\n   - **Community Engagement**: Measure how well the conference fostered a sense of community among attendees, presenters, and AI researchers.\\n\\nBy considering these factors, one can gain a comprehensive understanding of the quality of an AAAI conference.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"how to judge the quality of AAAI conference?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The question \"What is 2 + 2?\" is a simple arithmetic operation in programming.\\n\\nIn most programming languages (like Python, Java, or C), `2 + 2` would evaluate to:\\n\\n```\\n4\\n```\\n\\nThis means that when you add two numbers together (2 and another 2), the result is 4.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is 2 + 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
