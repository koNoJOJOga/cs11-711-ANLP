{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load environment variables from .env file\n",
    "_ = load_dotenv()\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: list[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model=\"qwen2.5:7b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high leveloutline of an essay. Write such an outline for the user \\\n",
    "provided topic. Give an outline of the essay along with any relevant notes or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITTER_PROMPT = \"\"\"You are an essay assistant tasked with writing excell Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous essay. \\ \n",
    "Utilize all the information below as needed:\n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission.\\ \n",
    "Generate critique and recommentdations for the user's submission. \\ \n",
    "provide detailed recommendations, including requests for length, depth, and clarity. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information \\\n",
    "that can be used when writing the following essay. \\\n",
    "Generate a list of search queries that will gather any \\\n",
    "relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a research assistant helping to improve an academic essay.\n",
    "I will provide you with critical feedback about an essay. Your task is to generate specific research queries \n",
    "that will help address the weaknesses mentioned in the critique.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Analyze the critique carefully to identify knowledge gaps and weaknesses\n",
    "2. Generate 3-5 specific search queries that would help address these issues\n",
    "3. Focus on factual information, statistics, examples, or counter-arguments needed\n",
    "4. Make each query concise (5-10 words) but specific enough for search engines\n",
    "5. Return ONLY a JSON-compatible structure with a 'queries' list containing the search queries\n",
    "\n",
    "OUTPUT FORMAT EXAMPLE:\n",
    "{ \"queries\": [ \"machine learning healthcare applications statistics\", \"ai ethics case studies 2023\", \"deep learning vs traditional algorithms comparison\", \"neural network training dataset size requirements\" ] }\" \\\n",
    "\"\" \\\n",
    "\"\n",
    "DO NOT include any explanations, introductions or notes outside the JSON structure.\n",
    "If you're uncertain about what research is needed based on the critique, focus on the \n",
    "main topic of the essay combined with factual research terms like \"statistics\", \n",
    "\"examples\", \"case studies\", \"comparison\", etc.\n",
    "\n",
    "NOW, based on the following critique, generate appropriate research queries:\n",
    "\n",
    "CRITIQUE:\n",
    "{{critique}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将导入Tavily client而不是tool，因为我们在使用一些非传统方式使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个`node`将接收状态，然后创建一个消息列表。其中一个将是`PLAN_PROMPT`，那将是`SystemMessage`。然后创建`HumanMessage`，传入我们要做的`task`。然后我们将得到一个`response`，我们将取得这个消息的信息将其设置为`plan`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个`node`是接收`plan`并进行一些`research`。首先会生成一些`query`，这基本上是在说，我们将要调用它的响应将是我们之前调用的pydantic object，其中包含查询列表。所以我们将在消息列表上调用invoke。我们拿到了`RESEARCH_PLAN_PROMPT`，然后创建`HumanMessage`，传入我们要做的`task`。我们将会获取我们当前文档的列表，我们将用他们来撰写这篇essay。然后我们将循环遍历`query`，并在travily中进行搜索，我们取得`result`后，会将其附加到`content`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"])\n",
    "    ])\n",
    "    content = state.get('content', [])  # 使用get方法，如果键不存在则返回空列表\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于生成节点，我们要做的第一件事是准备内容。然后我们将创建`user_message`，我们将`plan`和`task`结合起来。然后创建一个消息列表，首先是一个带有写作提示的`SystemMessage`我们在其中格式化`content`。我们把信息传递给消息队列，得到一个响应。然后我们会更新修订号，这可以跟踪我们做了多少次修订。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\n Here is my plan:\\n\\n {state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITTER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成之后，我们现在需要一个反思节点。反思节点会将反思提示作为系统提示，然后会提取`draft`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state[\"draft\"])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`with_structured_output(Queries)`方法将模型输出强制转换为预定义的`Queries`结构体，确保输出格式规范。然后，系统将批评内容作为输入，让AI分析论文的弱点并生成针对性查询。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def research_critique_node(state: AgentState):\n",
    "#     queries = model.with_structured_output(Queries).invoke([\n",
    "#         SystemMessage(content=RESERCH_CRITIQUE_PROMPT),\n",
    "#         HumanMessage(content=state[\"critique\"])\n",
    "#     ])\n",
    "#     content = state.get('content', [])  # 使用get方法，避免KeyError\n",
    "#     for q in queries.queries:\n",
    "#         response = tavily.search(query=q, max_results=2)\n",
    "#         for r in response['results']:\n",
    "#             content.append(r['content'])\n",
    "#     return {\"content\": content}\n",
    "def research_critique_node(state: AgentState):\n",
    "    try:\n",
    "        # 尝试获取结构化输出\n",
    "        queries = model.with_structured_output(Queries).invoke([\n",
    "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "            HumanMessage(content=state[\"critique\"])\n",
    "        ])\n",
    "        \n",
    "        # 检查queries是否为None或不具有预期结构\n",
    "        if queries is None or not hasattr(queries, 'queries') or not queries.queries:\n",
    "            # 创建基于文章主题的默认查询\n",
    "            print(\"警告: 结构化输出生成失败，使用默认查询\")\n",
    "            default_queries = [\n",
    "                \"Messi Ronaldo comparison statistics\", \n",
    "                \"Best soccer player achievements\", \n",
    "                \"Football player career highlights\"\n",
    "            ]\n",
    "            \n",
    "            content = state.get('content', [])\n",
    "            # 使用默认查询\n",
    "            for q in default_queries:\n",
    "                response = tavily.search(query=q, max_results=2)\n",
    "                for r in response['results']:\n",
    "                    content.append(r['content'])\n",
    "                    \n",
    "            return {\"content\": content}\n",
    "        \n",
    "        # 如果queries结构正确，按原计划继续\n",
    "        content = state.get('content', [])\n",
    "        for q in queries.queries:\n",
    "            response = tavily.search(query=q, max_results=2)\n",
    "            for r in response['results']:\n",
    "                content.append(r['content'])\n",
    "                \n",
    "        return {\"content\": content}\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 记录错误\n",
    "        print(f\"research_critique_node中出现错误: {e}\")\n",
    "        \n",
    "        # 错误发生时返回现有内容\n",
    "        return {\"content\": state.get('content', [])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将查看修订号，如果大于最大修订次数，我们将结束，否则返回`\"reflect\"`继续反思。注意这是在生成步骤后的操作，我们要么完成，要么进入评论循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先初始化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x120d59840>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x120d59840>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")  # 设置一个入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x120d59840>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 条件边\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    should_continue,\n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x120d59840>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': '### High-Level Outline: What is the Difference Between Langchain and LangSmith?\\n\\n#### Introduction\\n- **Introduction to AI Tools**: Briefly introduce the context of AI tools in software development.\\n- **Purpose of the Essay**: Explain that this essay aims to highlight the differences between two specific AI tools, Langchain and LangSmith.\\n\\n#### Section 1: Overview of Langchain\\n- **Definition and Purpose**: Define what Langchain is and its primary purpose or function.\\n- **Key Features**:\\n  - List key features such as integration capabilities, API structure, and any unique selling points.\\n- **Use Cases**: Provide examples of how Langchain can be used in real-world scenarios.\\n\\n#### Section 2: Overview of LangSmith\\n- **Definition and Purpose**: Define what LangSmith is and its primary purpose or function.\\n- **Key Features**:\\n  - List key features such as integration capabilities, API structure, and any unique selling points.\\n- **Use Cases**: Provide examples of how LangSmith can be used in real-world scenarios.\\n\\n#### Section 3: Comparative Analysis\\n- **Similarities**: Highlight any similarities between the two tools to provide a basis for comparison.\\n- **Differences**:\\n  - **Functionality**: Compare their core functionalities and capabilities.\\n  - **Integration**: Discuss differences in how they integrate with other systems or platforms.\\n  - **Performance**: Analyze performance metrics such as speed, efficiency, and reliability.\\n  - **User Interface**: Describe the user interface and experience for each tool.\\n- **Use Case Scenarios**: Provide specific use case scenarios where one might be preferred over the other.\\n\\n#### Section 4: Pros and Cons\\n- **Langchain Pros**:\\n  - List advantages such as ease of use, cost-effectiveness, or advanced features.\\n- **Langchain Cons**:\\n  - Discuss potential drawbacks like limitations in functionality or support.\\n- **LangSmith Pros**:\\n  - List advantages such as ease of use, cost-effectiveness, or advanced features.\\n- **LangSmith Cons**:\\n  - Discuss potential drawbacks like limitations in functionality or support.\\n\\n#### Section 5: Conclusion\\n- **Summary**: Recap the main differences and key points discussed.\\n- **Recommendations**: Provide recommendations based on specific needs and requirements.\\n- **Future Outlook**: Briefly discuss future developments or trends for both tools.\\n\\n#### Notes:\\n- Ensure to include up-to-date information as of the latest version or release date.\\n- Use credible sources such as official documentation, user reviews, and industry reports.\\n- Consider including visual aids like charts or diagrams if relevant.'}}\n",
      "{'research_plan': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown – Be on the Right Side of Change Langchain vs Langsmith: Unpacking the AI Language Model Showdown If Langchain is the engine, LangSmith is the dashboard helping you monitor and debug the performance of your LLM applications. It’s about bringing your ideas from initial prototype to a robust production environment, using tools like LangSmith for crafting and LangChain for deployment. Remember, while LangSmith helps you build, test, and debug your prototype, LangChain offers the structure for deploying and monitoring your final product in a live environment. Whether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.', 'LangChain is an open-source framework designed to streamline the development of applications leveraging language models. It offers modular components to connect various tasks, enabling a seamless', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', 'Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.']}}\n",
      "{'generate': {'draft': \"### High-Level Outline: What is the Difference Between Langchain and LangSmith?\\n\\n#### Introduction\\n- **Introduction to AI Tools**: Briefly introduce the context of AI tools in software development.\\n- **Purpose of the Essay**: Explain that this essay aims to highlight the differences between two specific AI tools, Langchain and LangSmith.\\n\\n#### Section 1: Overview of Langchain\\n- **Definition and Purpose**: Define what Langchain is and its primary purpose or function.\\n- **Key Features**:\\n  - List key features such as integration capabilities, API structure, and any unique selling points.\\n- **Use Cases**: Provide examples of how Langchain can be used in real-world scenarios.\\n\\n#### Section 2: Overview of LangSmith\\n- **Definition and Purpose**: Define what LangSmith is and its primary purpose or function.\\n- **Key Features**:\\n  - List key features such as integration capabilities, API structure, and any unique selling points.\\n- **Use Cases**: Provide examples of how LangSmith can be used in real-world scenarios.\\n\\n#### Section 3: Comparative Analysis\\n- **Similarities**: Highlight any similarities between the two tools to provide a basis for comparison.\\n- **Differences**:\\n  - **Functionality**: Compare their core functionalities and capabilities.\\n  - **Integration**: Discuss differences in how they integrate with other systems or platforms.\\n  - **Performance**: Analyze performance metrics such as speed, efficiency, and reliability.\\n  - **User Interface**: Describe the user interface and experience for each tool.\\n- **Use Case Scenarios**: Provide specific use case scenarios where one might be preferred over the other.\\n\\n#### Section 4: Pros and Cons\\n- **Langchain Pros**:\\n  - List advantages such as ease of use, cost-effectiveness, or advanced features.\\n  - Discuss potential drawbacks like limitations in functionality or support.\\n- **LangSmith Pros**:\\n  - List advantages such as ease of use, cost-effectiveness, or advanced features.\\n  - Discuss potential drawbacks like limitations in functionality or support.\\n\\n#### Section 5: Conclusion\\n- **Summary**: Recap the main differences and key points discussed.\\n- **Recommendations**: Provide recommendations based on specific needs and requirements.\\n- **Future Outlook**: Briefly discuss future developments or trends for both tools.\\n\\n### Detailed Essay\\n\\n---\\n\\n#### Introduction\\nIn today's rapidly evolving landscape of artificial intelligence (AI), developers are increasingly turning to specialized tools to streamline the development, deployment, and monitoring of language models. Two such tools that have gained significant traction in this domain are Langchain and LangSmith. Both offer unique functionalities and serve different stages of AI model development. This essay aims to highlight the differences between these two tools by providing an overview of their features, use cases, and comparative analysis.\\n\\n#### Section 1: Overview of Langchain\\n**Definition and Purpose**: \\nLangchain is an open-source framework designed to streamline the development of applications leveraging language models. It offers modular components that enable developers to connect various tasks seamlessly, making it easier to build scalable AI solutions.\\n\\n**Key Features**:\\n- **Modular Architecture**: Langchain’s architecture allows for easy integration with different libraries and frameworks.\\n- **Ease of Use**: The framework provides a user-friendly interface and comprehensive documentation, facilitating quick setup and deployment.\\n- **Scalability**: It supports the development of large-scale applications by providing robust infrastructure.\\n\\n**Use Cases**:\\nLangchain can be used in various real-world scenarios such as building chatbots, natural language processing (NLP) systems, and content generation tools. For instance, a company developing an AI-driven customer service platform could use Langchain to integrate multiple NLP models and manage the entire workflow efficiently.\\n\\n#### Section 2: Overview of LangSmith\\n**Definition and Purpose**: \\nLangSmith is a tool focused on the deployment and monitoring of language models in production environments. It provides a comprehensive suite of features for managing model performance, tracking metrics, and ensuring reliability.\\n\\n**Key Features**:\\n- **Model Management**: LangSmith offers robust tools for deploying, scaling, and managing multiple language models.\\n- **Monitoring and Logging**: The tool includes advanced logging and monitoring capabilities to track the performance of deployed models in real-time.\\n- **Security and Compliance**: It ensures that models are secure and compliant with industry standards.\\n\\n**Use Cases**:\\nLangSmith is particularly useful in scenarios where continuous monitoring and management of AI models are critical. For example, a financial institution might use LangSmith to deploy predictive models for fraud detection while ensuring they meet regulatory requirements and performance benchmarks.\\n\\n#### Section 3: Comparative Analysis\\n**Similarities**: \\nBoth Langchain and LangSmith share the common goal of enhancing the development and deployment of language models. They both offer comprehensive documentation and support, making them accessible to a wide range of users.\\n\\n**Differences**:\\n- **Functionality**:\\n  - **Langchain**: Focuses on the initial stages of model development, including integration and setup.\\n  - **LangSmith**: Concentrates on the deployment and monitoring phases, ensuring models perform optimally in production environments.\\n\\n- **Integration**:\\n  - **Langchain**: Provides a modular architecture that can integrate with various libraries and frameworks.\\n  - **LangSmith**: Offers specialized tools for managing deployed models, including advanced logging and security features.\\n\\n- **Performance**:\\n  - **Langchain**: Optimized for development speed and ease of use.\\n  - **LangSmith**: Designed to ensure high performance and reliability in production environments.\\n\\n- **User Interface**:\\n  - **Langchain**: User-friendly interface with comprehensive documentation.\\n  - **LangSmith**: More focused on advanced features, potentially requiring a steeper learning curve.\\n\\n**Use Case Scenarios**:\\n- For developers building AI applications from scratch, Langchain would be the preferred choice due to its ease of use and modular architecture.\\n- For organizations that need robust monitoring and management tools for deployed models, LangSmith would be more suitable.\\n\\n#### Section 4: Pros and Cons\\n**Langchain Pros**:\\n- **Ease of Use**: Simplifies the development process with a user-friendly interface.\\n- **Modular Architecture**: Facilitates integration with various libraries and frameworks.\\n- **Scalability**: Supports large-scale applications efficiently.\\n\\n**Langchain Cons**:\\n- **Limited Monitoring Tools**: Primarily focused on development, lacking advanced monitoring features.\\n- **Support for Production Environments**: Not as robust in managing deployed models compared to LangSmith.\\n\\n**LangSmith Pros**:\\n- **Advanced Monitoring and Logging**: Ensures high performance and reliability in production environments.\\n- **Security and Compliance**: Provides tools to meet regulatory requirements.\\n- **Comprehensive Model Management**: Offers a wide range of features for deploying and scaling models.\\n\\n**LangSmith Cons**:\\n- **Steeper Learning Curve**: May require more time and effort to learn due to its advanced features.\\n- **Cost**: Potentially higher costs associated with comprehensive monitoring and management tools.\\n\\n#### Section 5: Conclusion\\nIn summary, Langchain and LangSmith serve different stages of AI model development. Langchain is ideal for developers looking to streamline the initial setup and integration phases, while LangSmith excels in providing robust monitoring and management tools for deployed models. The choice between these tools depends on specific needs such as ease of use, scalability requirements, or advanced monitoring capabilities.\\n\\nFor future developments, both tools are likely to see continued improvements in user experience, performance optimization, and additional features that cater to evolving AI development trends. As the field of AI continues to grow, tools like Langchain and LangSmith will play crucial roles in enabling developers to build and deploy sophisticated language models efficiently.\\n\\n---\\n\\nThis structured approach ensures a comprehensive comparison between Langchain and LangSmith, providing valuable insights for users considering these tools for their AI projects.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': \"Your essay provides a solid foundation for comparing Langchain and LangSmith, but there are several areas where it can be enhanced in terms of length, depth, and clarity. Here are detailed recommendations to improve your submission:\\n\\n### Recommendations\\n\\n#### Introduction\\n- **Length**: Aim for 100-200 words.\\n- **Depth**: Provide a brief overview of the context and importance of AI tools in software development.\\n- **Clarity**: Ensure the purpose is clearly stated.\\n\\n**Revised Section:**\\nIn today's rapidly evolving landscape, developers are increasingly leveraging specialized tools to streamline the development, deployment, and monitoring of language models. Tools like Langchain and LangSmith have gained significant traction by offering unique functionalities tailored to different stages of AI model development. This essay aims to highlight the differences between these two tools by providing an overview of their features, use cases, and comparative analysis.\\n\\n#### Section 1: Overview of Langchain\\n- **Length**: Aim for 200-300 words.\\n- **Depth**: Include more detailed descriptions of key features and real-world applications.\\n- **Clarity**: Ensure each point is clearly articulated.\\n\\n**Revised Section:**\\n**Definition and Purpose**:\\nLangchain is an open-source framework designed to streamline the development of applications leveraging language models. It offers a modular architecture that enables developers to connect various tasks seamlessly, making it easier to build scalable AI solutions.\\n\\n**Key Features**:\\n- **Modular Architecture**: Langchain’s architecture allows for easy integration with different libraries and frameworks.\\n- **Ease of Use**: The framework provides a user-friendly interface and comprehensive documentation, facilitating quick setup and deployment.\\n- **Scalability**: It supports the development of large-scale applications by providing robust infrastructure.\\n\\n**Use Cases**:\\nLangchain can be used in various real-world scenarios such as building chatbots, natural language processing (NLP) systems, and content generation tools. For instance, a company developing an AI-driven customer service platform could use Langchain to integrate multiple NLP models and manage the entire workflow efficiently. Additionally, it is well-suited for projects requiring rapid prototyping and iterative development.\\n\\n#### Section 2: Overview of LangSmith\\n- **Length**: Aim for 200-300 words.\\n- **Depth**: Include more detailed descriptions of key features and real-world applications.\\n- **Clarity**: Ensure each point is clearly articulated.\\n\\n**Revised Section:**\\n**Definition and Purpose**:\\nLangSmith is a tool designed to focus on the deployment and monitoring phases, ensuring that models perform optimally in production environments. It offers specialized tools for managing deployed models, including advanced logging and security features.\\n\\n**Key Features**:\\n- **Advanced Monitoring and Logging**: Ensures high performance and reliability in production environments.\\n- **Security and Compliance**: Provides tools to meet regulatory requirements.\\n- **Comprehensive Model Management**: Offers a wide range of features for deploying and scaling models.\\n\\n**Use Cases**:\\nLangSmith is ideal for organizations that need robust monitoring and management tools for deployed models. For example, financial institutions might use LangSmith to ensure compliance with data privacy regulations while maintaining high performance in their AI systems. It is also suitable for enterprises looking to deploy complex models in production environments where reliability and security are critical.\\n\\n#### Section 3: Comparative Analysis\\n- **Length**: Aim for 400-500 words.\\n- **Depth**: Provide a detailed comparison of key features, integration capabilities, performance, user interface, and cost.\\n- **Clarity**: Use clear headings to organize the information logically.\\n\\n**Revised Section:**\\n**Integration Capabilities**:\\n- **Langchain**: Focuses on development speed and ease of use. It provides a modular architecture that can integrate with various libraries and frameworks, making it ideal for rapid prototyping and iterative development.\\n- **LangSmith**: Concentrates on deployment and monitoring phases. While it offers specialized tools for managing deployed models, its integration capabilities are more focused on ensuring high performance in production environments.\\n\\n**Performance**:\\n- **Langchain**: Optimized for development speed and ease of use. It is well-suited for projects requiring quick setup and iterative development.\\n- **LangSmith**: Designed to ensure high performance and reliability in production environments. Its advanced monitoring tools help maintain optimal performance, making it suitable for complex models deployed in real-world scenarios.\\n\\n**User Interface**:\\n- **Langchain**: User-friendly interface with comprehensive documentation, facilitating easy onboarding and use.\\n- **LangSmith**: More focused on advanced features, potentially requiring a steeper learning curve but offering more robust monitoring tools.\\n\\n**Cost**:\\n- **Langchain**: Generally lower cost due to its focus on development and ease of use. It is suitable for projects where initial setup and rapid prototyping are the primary concerns.\\n- **LangSmith**: Potentially higher costs associated with comprehensive monitoring and management tools, making it a better fit for organizations that need robust production support.\\n\\n**Use Case Scenarios**:\\n- For developers building AI applications from scratch, Langchain would be the preferred choice due to its ease of use and modular architecture. It is ideal for projects requiring rapid prototyping and iterative development.\\n- For organizations that need robust monitoring and management tools for deployed models, LangSmith would be more suitable. Its advanced features ensure high performance and reliability in production environments.\\n\\n#### Section 4: Pros and Cons\\n- **Length**: Aim for 200-300 words.\\n- **Depth**: Provide a detailed list of pros and cons for each tool.\\n- **Clarity**: Use clear headings to organize the information logically.\\n\\n**Revised Section:**\\n**Langchain Pros**:\\n- **Ease of Use**: Simplifies the development process with a user-friendly interface.\\n- **Modular Architecture**: Facilitates integration with various libraries and frameworks, making it ideal for rapid prototyping.\\n- **Scalability**: Supports large-scale applications efficiently.\\n\\n**Langchain Cons**:\\n- **Limited Monitoring Tools**: Primarily focused on development, lacking advanced monitoring features.\\n- **Support for Production Environments**: Not as robust in managing deployed models compared to LangSmith.\\n\\n**LangSmith Pros**:\\n- **Advanced Monitoring and Logging**: Ensures high performance and reliability in production environments.\\n- **Security and Compliance**: Provides tools to meet regulatory requirements.\\n- **Comprehensive Model Management**: Offers a wide range of features for deploying and scaling models.\\n\\n**LangSmith Cons**:\\n- **Steeper Learning Curve**: May require more time and effort to learn due to its advanced features.\\n- **Cost**: Potentially higher costs associated with comprehensive monitoring and management tools.\\n\\n#### Section 5: Conclusion\\n- **Length**: Aim for 100-200 words.\\n- **Depth**: Summarize the key points and provide a clear recommendation based on specific needs.\\n- **Clarity**: Ensure the conclusion is concise and impactful.\\n\\n**Revised Section:**\\nIn summary, Langchain and LangSmith serve different stages of AI model development. Langchain is ideal for developers looking to streamline the initial setup and integration phases, while LangSmith excels in providing robust monitoring and management tools for deployed models. The choice between the two depends on specific project requirements. For rapid prototyping and iterative development, Langchain is the better fit. For organizations needing high performance and reliability in production environments, LangSmith offers comprehensive support.\\n\\nBy carefully considering these factors, you can make an informed decision that aligns with your project's needs and goals.\\n\\n---\\n\\nThis revised version provides a more structured and detailed analysis of both tools, ensuring clarity and depth in each section. It also includes clear headings to guide the reader through the comparison process.\"}}\n",
      "警告: 结构化输出生成失败，使用默认查询\n",
      "{'research_critique': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown – Be on the Right Side of Change Langchain vs Langsmith: Unpacking the AI Language Model Showdown If Langchain is the engine, LangSmith is the dashboard helping you monitor and debug the performance of your LLM applications. It’s about bringing your ideas from initial prototype to a robust production environment, using tools like LangSmith for crafting and LangChain for deployment. Remember, while LangSmith helps you build, test, and debug your prototype, LangChain offers the structure for deploying and monitoring your final product in a live environment. Whether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.', 'LangChain is an open-source framework designed to streamline the development of applications leveraging language models. It offers modular components to connect various tasks, enabling a seamless', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', 'Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"Messi vs Ronaldo - All Time Career Goals and Stats Messi vs Ronaldo All Time Stats The stats show that Ronaldo consistently has more shots on goal than Messi, totalling 4827 shots in the games we have this data for, compared to Messi's 3837 shots. In terms of the all time career stats, Messi has now scored 66 free kick goals compared to Ronaldo's 64 free kick goals. Ronaldo has won the Puskas award for best goal in a calendar year (from 2 nominations), whereas Messi has so far failed to win this award despite being nominated 7 times. Ronaldo however dominates the Champions League record books, with most goals, most assists, most free kick goals, most hat-tricks (shared with Messi), and most goals in a single season.\", 'statistics; Premium service; Player comparison. This tool can be used to compare two players of your choice. To do this, simply enter your desired players in the two search fields and click the \"Compare\" button. ... Cristiano Ronaldo Lionel Messi; Matches Minutes Assists Goals min W D W min Goals Assists; 35: 2.896: 1: 20: 2.979: 10: 9: 16: 3', \"Major Achievements:\\xa01998 Ballon d'Or, 1998, 2000 & 2003 FIFA World Player of the Year, 2002 UEFA Club Footballer of the Year, 2000/01 Serie A Footballer of the Year, UEFA Champions League Best Player of the Past 20 Years, L'Equipe Best French Player of All Time, 2006 FIFA World Cup Golden Ball, only player to be named Player of the Year in three of the top five leagues, most goals in FIFA World Cup finals, 1998 FIFA World Cup, 2000 UEFA European Championships,\\xa0one Champions League, two Scudetti, one La Liga title, one Intercontinental Cup. Zinedine Zidane was one beautiful wizard with a ball at his feet.\", 'Current Club: Real Madrid Key Achievements: Champions League winner, La Liga champion. Style of Play: A versatile player capable of playing as a midfielder or left-back, Camavinga is known for his ball-winning skills and tactical intelligence. 13. Rodrygo (Real Madrid) Wages: Estimated €220,000 per week Current Club: Real Madrid Key Achievements: Champions League and La Liga winner.', \"Lawrence Taylor's career highlights with the New York Giants!#NFLLegendsThe NFL Throwback is your home for all things NFL history.Check out our other channel\", 'Hall of Fame Cornerback, Deion \"Primetime\" Sanders, full career highlights with the Atlanta Falcons, San Francisco 49ers, Dallas Cowboys, Washington Redskins']}}\n",
      "{'generate': {'draft': '### High-Level Outline: What is the Difference Between Langchain and LangSmith?\\n\\n#### Introduction\\n- **Introduction to AI Tools**: Briefly introduce the context of AI tools in software development.\\n- **Purpose of the Essay**: Explain that this essay aims to highlight the differences between two specific AI tools, Langchain and LangSmith.\\n\\n#### Section 1: Overview of Langchain\\n- **Definition and Purpose**: Define what Langchain is and its primary purpose or function.\\n- **Key Features**:\\n  - Integration capabilities with various frameworks and platforms.\\n  - API structure for seamless integration into existing projects.\\n  - Unique selling points such as ease of deployment and flexibility.\\n- **Use Cases**: Provide examples of how Langchain can be used in real-world scenarios, such as building custom AI models or integrating machine learning algorithms.\\n\\n#### Section 2: Overview of LangSmith\\n- **Definition and Purpose**: Define what LangSmith is and its primary purpose or function.\\n- **Key Features**:\\n  - Integration capabilities with various frameworks and platforms.\\n  - API structure for seamless integration into existing projects.\\n  - Unique selling points such as advanced monitoring, debugging tools, and real-time analytics.\\n- **Use Cases**: Provide examples of how LangSmith can be used in real-world scenarios, such as deploying and managing AI models in production environments.\\n\\n#### Section 3: Comparative Analysis\\n- **Similarities**:\\n  - Both are designed to facilitate the integration of AI into software development projects.\\n  - They both offer APIs for easy integration with existing systems.\\n- **Differences**:\\n  - **Functionality**: Langchain focuses more on the deployment and management of custom AI models, while LangSmith offers advanced monitoring and debugging tools.\\n  - **Integration**: Both support a wide range of frameworks but differ in their specific integrations. Langchain might have a broader focus on model deployment, whereas LangSmith emphasizes real-time analytics and performance monitoring.\\n  - **Performance**: Langchain is optimized for speed and efficiency in deploying models, while LangSmith ensures robust performance through advanced monitoring tools.\\n  - **User Interface**: Langchain provides a straightforward interface for deploying models, while LangSmith offers more detailed insights and control over the deployed models.\\n\\n#### Section 4: Pros and Cons\\n- **Langchain Pros**:\\n  - Ease of use in deploying custom AI models.\\n  - Cost-effective for small to medium projects.\\n  - Flexibility in integrating with various frameworks.\\n- **Langchain Cons**:\\n  - Limited advanced monitoring features compared to LangSmith.\\n  - May require more manual setup and configuration.\\n\\n- **LangSmith Pros**:\\n  - Advanced monitoring, debugging, and real-time analytics.\\n  - Robust performance management tools.\\n  - Detailed insights into model performance in production environments.\\n- **LangSmith Cons**:\\n  - Higher cost due to advanced features.\\n  - Steeper learning curve for users unfamiliar with detailed monitoring tools.\\n\\n#### Section 5: Conclusion\\n- **Summary**: Recap the main differences and key points discussed.\\n- **Recommendations**: Provide recommendations based on specific needs and requirements, such as choosing Langchain for simpler projects or LangSmith for more complex deployments requiring advanced analytics.\\n- **Future Outlook**: Briefly discuss future developments or trends for both tools, noting that both are likely to see continued improvements in their respective areas.\\n\\n#### Notes:\\n- Ensure to include up-to-date information as of the latest version or release date.\\n- Use credible sources such as official documentation, user reviews, and industry reports.\\n- Consider including visual aids like charts or diagrams if relevant.', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        interrupt_after=['planner', 'generate', 'reflect', 'research_plan', 'research_critique']\n",
    "    )\n",
    "    for s in graph.stream({\n",
    "        'task': \"What different between Langchain and langsmith?\",\n",
    "        \"max_revisions\": 2,\n",
    "        \"revision_number\": 1\n",
    "    }, thread):\n",
    "        print(s)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
